{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import sys\n",
    "from os import getcwd\n",
    "from os.path import dirname\n",
    "path = dirname(dirname(getcwd()))\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MintPy.interpret_toolkit import InterpretToolkit\n",
    "from MintPy.utils import combine_top_features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the utility of MintPy, we are using a XXX dataset. We are loading three pre-fit classifiers from scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target feature\n",
    "TARGET_COLUMN = 'cat_rt'\n",
    "\n",
    "# Load the model objects. In this case, we are using 3 \n",
    "# popular models availabe in scikit-learn \n",
    "model_fname = ['RandomForest.pkl', 'LogisticRegression.pkl', 'GradientBoostingClassifier.pkl']\n",
    "model_objs = [load(fname) for fname in model_fname]\n",
    "\n",
    "# Load the training dataset \n",
    "data  = pd.read_csv('example_data.csv')\n",
    "targets = data[TARGET_COLUMN].values\n",
    "\n",
    "# only want to use these columns below\n",
    "cols_to_use = ['dllwave_flux', 'dwpt2m', 'fric_vel', 'gflux', 'high_cloud',\n",
    "            'lat_hf', 'low_cloud', 'mid_cloud', 'sat_irbt', 'sens_hf',\n",
    "            'sfcT_hrs_ab_frez', 'sfcT_hrs_bl_frez', 'sfc_rough', 'sfc_temp',\n",
    "            'swave_flux','temp2m', 'tmp2m_hrs_ab_frez', 'tmp2m_hrs_bl_frez',\n",
    "            'tot_cloud', 'uplwav_flux','vbd_flux', 'vdd_flux','wind10m',\n",
    "            'date_marker', 'urban','rural','d_ground','d_rad_d','d_rad_u',\n",
    "            'hrrr_dT']\n",
    "\n",
    "units = ['W m$^{-2}$', '$^\\circ$C', 'm s$^{-1}$', 'W m$^{-2}$', '%', 'W m$^{-2}$', '%', '%', \n",
    "         '$^\\circ$C', 'W m$^{-2}$', 'hrs', 'hrs', 'unitless','$^\\circ$C', 'W m$^{-2}$', '$^\\circ$C', \n",
    "         'hrs', 'hrs', '%', 'W m$^{-2}$', 'W m$^{-2}$', 'W m$^{-2}$', 'm s$^{-1}$', 'days', 'unitless', \n",
    "         'unitless', 'W m$^{-2}$', 'W m$^{-2}$', 'W m$^{-2}$', '$^\\circ$C']\n",
    "\n",
    "pretty_names = [r'$\\lambda_{\\downarrow}$', '$T_{d}$', '$V_{fric}$', 'Gflux', '$Cloud_{high}$',\n",
    " '$Lat_{F}$', '$Cloud_{low}$', '$Cloud_{mid}$', 'IRBT', '$Sens_{F}$',\n",
    " 'Hours $T_{sfc}$ $> $0', 'Hours $T_{sfc}$ $<= $0', 'SfcRough', '$T_{sfc}$',\n",
    " '$I_{S}$', '$T_{2m}$', 'Hours $T_{2m}$ $> $0', 'Hours $T_{2m}$ $<= $0',\n",
    " '$Cloud_{Tot}$', r'$\\lambda_{\\uparrow}$', 'VBD', 'VDD', '10m wind',\n",
    " 'Date marker', 'Urban', 'Rural', 'Diff1', 'Diff2', 'Diff3',\n",
    " '$T_{sfc}$ - $T_{2m}$']\n",
    "\n",
    "feature_units = {c : u for c,u in zip(cols_to_use, units)}\n",
    "readable_feature_names = {c : u for c,u in zip(cols_to_use, pretty_names)}\n",
    "\n",
    "# get predictor subset of dataframe (only the predictors used in training the model)\n",
    "examples = data[cols_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing InterpretToolkit\n",
    "\n",
    "To initialize `InterpretToolkit`, requires a model object (e.g., a trained sci-kit learn model object) or a list of model objects and examples and targets to evalute the model(s) on. `examples` and `targets` can be `pandas.DataFrame` or `numpy.array`, but if you are using arrays, then you must provide the feature names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "myInterpreter = InterpretToolkit(model=model_objs, \n",
    "                             examples=examples, \n",
    "                             targets=targets,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_vars = ['dllwave_flux', 'dwpt2m', 'sfc_temp', 'temp2m', 'uplwav_flux']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Dependence Plots\n",
    "\n",
    "Once we known what features are important, we explore their functional relationship with the target variable. MintPy has a built-in function to take the important features from multiple model turn it into a single list with any duplicate features removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3 processors...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'prediction_method' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda3/envs/deep/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/monte.flora/MintPy/multiprocessing_utils.py\", line 27, in __call__\n    result = self.__callable(*args, **kwargs)\n  File \"/Users/monte.flora/MintPy/partial_dependence.py\", line 174, in compute_partial_dependence\n    predictions = prediction_method(examples_temp)\nUnboundLocalError: local variable 'prediction_method' referenced before assignment\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1fec743c1f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyInterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_pd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimportant_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnjobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m fig, axes = myInterpreter.plot_pd(feature_units=feature_units,\n\u001b[1;32m      3\u001b[0m                                  readable_feature_names=readable_feature_names)\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Add some functionality to generate automatically generate user-friendly left y ticks marks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MintPy/interpret_toolkit.py\u001b[0m in \u001b[0;36mcalc_pd\u001b[0;34m(self, features, nbins, njobs, subsample, nbootstrap)\u001b[0m\n\u001b[1;32m    125\u001b[0m         pd_object = PartialDependence(model=self.models, \n\u001b[1;32m    126\u001b[0m                                       \u001b[0mexamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                       model_output=self.model_output)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         results = pd_object.run_pd(features=features, \n",
      "\u001b[0;32m~/MintPy/partial_dependence.py\u001b[0m in \u001b[0;36mrun_pd\u001b[0;34m(self, features, nbins, njobs, subsample, nbootstrap)\u001b[0m\n\u001b[1;32m     81\u001b[0m                                     [nbootstrap])\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         results = run_parallel(\n\u001b[0m\u001b[1;32m     84\u001b[0m                    \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_partial_dependence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                    \u001b[0margs_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MintPy/multiprocessing_utils.py\u001b[0m in \u001b[0;36mrun_parallel\u001b[0;34m(func, args_iterator, kwargs, nprocs_to_use)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# list of dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_objects\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MintPy/multiprocessing_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# list of dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_objects\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deep/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'prediction_method' referenced before assignment"
     ]
    }
   ],
   "source": [
    "myInterpreter.calc_pd(features=important_vars, nbootstrap=1, subsample=1.0, njobs=3)\n",
    "fig, axes = myInterpreter.plot_pd(feature_units=feature_units,\n",
    "                                 readable_feature_names=readable_feature_names)\n",
    "# Add some functionality to generate automatically generate user-friendly left y ticks marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulated Local Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myInterpreter.run_ale(features=important_vars, nbootstrap=1, subsample=1.0, njobs=3)\n",
    "fig, axes = myInterpreter.plot_ale(feature_units=feature_units,\n",
    "                                 readable_feature_names=readable_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Contributions (Random Forest Only)\n",
    "\n",
    "For random forest, it is possible to breakdown a prediction into a series of contributions from the predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = myInterpreter.run_tree_interpreter(performance_based=True, n_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = myInterpreter.plot_tree_interpreter(readable_feature_names=readable_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-order PDP and ALE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tuple = [('dllwave_flux', 'fric_vel'), ('dwpt2m', 'fric_vel'), ('gflux', 'high_cloud')]\n",
    "myInterpreter.run_pd(features=feature_tuple, nbootstrap=1, subsample=1.0, njobs=3)\n",
    "fig, axes = myInterpreter.plot_pd(feature_units=feature_units,\n",
    "                                readable_feature_names=readable_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tuple = [('dllwave_flux', 'dwpt2m'),('dwpt2m', 'fric_vel'), ('gflux', 'high_cloud')]\n",
    "myInterpreter.run_ale(features=feature_tuple, nbootstrap=1, subsample=1.0, njobs=3)\n",
    "fig, axes = myInterpreter.plot_ale(feature_units=feature_units,\n",
    "                                 readable_feature_names=readable_feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
